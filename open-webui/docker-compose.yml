# Open Web UI
services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.6.13
    container_name: open-webui-production
    restart: unless-stopped
    networks:
      - dockernet
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - 'OLLAMA_BASE_URL=http://ollama:11434'
      - ENABLE_RAG_WEB_SEARCH=True
      - RAG_WEB_SEARCH_ENGINE=searxng
      - RAG_WEB_SEARCH_RESULT_COUNT=3
      - RAG_WEB_SEARCH_CONCURRENT_REQUESTS=10
      - SEARXNG_QUERY_URL=https://localhost:8081/search?q=<query>
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /etc/timezone:/etc/timezone:ro
      - ${DATA:-/mnt/models/openwebui}:/app/backend/data
    depends_on:
      - litellm-proxy
    ports:
      - "8080:8080" # Add this line to expose the port
    extra_hosts:
      - host.docker.internal:host-gateway

  litellm-proxy:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm-proxy
    environment:
      - GOOGLE_API_KEY=${GOOGLE_API_KEY} # Reads the key from a .env file
    command: ["--model", "gemini/gemini-1.5-pro-latest", "--port", "8000", "--host", "0.0.0.0"]
    restart: unless-stopped
    networks:
      - dockernet

networks:
  dockernet:
    external: true